import requests
import json
import pandas as pd

# A list of all of the census-designated places, villages, and cities in Nassau and Suffolk Counties, from https://api.census.gov/data/2010/dec/sf1?get=NAME&for=place%20(or%20part):*&in=state:36%20county:059,103
places = ["ALBERTSON", "AMAGANSETT", "AMITYVILLE", "AQUEBOGUE", "ASHAROKEN", "ATLANTIC BEACH", "BABYLON", "BAITING HOLLOW", "BALDWIN", "BALDWIN HARBOR", "BARNUM ISLAND", "BAXTER ESTATES", "BAY PARK", "BAY SHORE", "BAYPORT", "BAYVILLE", "BAYWOOD", "BELLE TERRE", "BELLEROSE", "BELLEROSE TERRACE", "BELLMORE", "BELLPORT", "BETHPAGE", "BLUE POINT", "BOHEMIA", "BRENTWOOD", "BRIDGEHAMPTON", "BRIGHTWATERS", "BROOKHAVEN", "BROOKVILLE", "CALVERTON", "CAPTREE", "CARLE PLACE", "CEDARHURST", "CENTER MORICHES", "CENTEREACH", "CENTERPORT", "CENTRAL ISLIP", "CENTRE ISLAND", "COLD SPRING HARBOR", "COMMACK", "COPIAGUE", "CORAM", "COVE NECK", "CUTCHOGUE", "DEER PARK", "DERING HARBOR", "DIX HILLS", "EAST ATLANTIC BEACH", "EAST FARMINGDALE", "EAST GARDEN CITY", "EAST HAMPTON", "EAST HAMPTON NORTH", "EAST HILLS", "EAST ISLIP", "EAST MARION", "EAST MASSAPEQUA", "EAST MEADOW", "EAST MORICHES", "EAST NORTHPORT", "EAST NORWICH", "EAST PATCHOGUE", "EAST QUOGUE", "EAST ROCKAWAY", "EAST SETAUKET", "EAST SHOREHAM", "EAST WILLISTON", "EASTPORT", "EATONS NECK", "ELMONT", "ELWOOD", "FARMINGDALE", "FARMINGVILLE", "FIRE ISLAND", "FISHERS ISLAND", "FLANDERS", "FLORAL PARK", "FLOWER HILL", "FORT SALONGA", "FRANKLIN SQUARE", "FREEPORT", "GARDEN CITY", "GARDEN CITY PARK", "GARDEN CITY SOUTH", "GILGO", "GLEN COVE", "GLEN HEAD", "GLENWOOD LANDING", "GORDON HEIGHTS", "GREAT NECK", "GREAT NECK ESTATES", "GREAT NECK GARDENS", "GREAT NECK PLAZA", "GREAT RIVER", "GREENLAWN", "GREENPORT", "GREENPORT WEST", "GREENVALE", "HALESITE", "HAMPTON BAYS", "HARBOR HILLS", "HARBOR ISLE", "HAUPPAUGE", "HEAD OF THE HARBOR", "HEMPSTEAD", "HERRICKS", "HEWLETT", "HEWLETT BAY PARK", "HEWLETT HARBOR", "HEWLETT NECK", "HICKSVILLE", "HOLBROOK", "HOLTSVILLE", "HUNTINGTON", "HUNTINGTON BAY", "HUNTINGTON STATION", "INWOOD", "ISLAND PARK", "ISLANDIA", "ISLIP", "ISLIP TERRACE", "JAMESPORT", "JERICHO", "KENSINGTON", "KINGS PARK", "KINGS POINT", "LAKE GROVE", "LAKE RONKONKOMA", "LAKE SUCCESS", "LAKEVIEW", "LATTINGTOWN", "LAUREL", "LAUREL HOLLOW", "LAWRENCE", "LEVITTOWN", "LIDO BEACH", "LINDENHURST", "LLOYD HARBOR", "LOCUST VALLEY", "LONG BEACH", "LYNBROOK", "MALVERNE", "MALVERNE PARK OAKS", "MANHASSET", "MANHASSET HILLS", "MANORHAVEN", "MANORVILLE", "MASSAPEQUA", "MASSAPEQUA PARK", "MASTIC", "MASTIC BEACH", "MATINECOCK", "MATTITUCK", "MEDFORD", "MELVILLE", "MERRICK", "MIDDLE ISLAND", "MILL NECK", "MILLER PLACE", "MINEOLA", "MONTAUK", "MORICHES", "MOUNT SINAI", "MUNSEY PARK", "MUTTONTOWN", "NAPEAGUE", "NESCONSET", "NEW CASSEL", "NEW HYDE PARK", "NEW SUFFOLK", "NISSEQUOGUE", "NORTH AMITYVILLE", "NORTH BABYLON", "NORTH BAY SHORE", "NORTH BELLMORE", "NORTH BELLPORT", "NORTH GREAT RIVER", "NORTH HAVEN", "NORTH HILLS", "NORTH LINDENHURST", "NORTH LYNBROOK", "NORTH MASSAPEQUA", "NORTH MERRICK", "NORTH NEW HYDE PARK", "NORTH PATCHOGUE", "NORTH SEA", "NORTH VALLEY STREAM", "NORTH WANTAGH", "NORTHAMPTON", "NORTHPORT", "NORTHVILLE", "NORTHWEST HARBOR", "NOYACK", "OAK BEACH", "OAKDALE", "OCEAN BEACH", "OCEANSIDE", "OLD BETHPAGE", "OLD BROOKVILLE", "OLD FIELD", "OLD WESTBURY", "ORIENT", "OYSTER BAY", "OYSTER BAY COVE", "PATCHOGUE", "PECONIC", "PLAINEDGE", "PLAINVIEW", "PLANDOME", "PLANDOME HEIGHTS", "PLANDOME MANOR", "POINT LOOKOUT", "POQUOTT", "PORT JEFFERSON", "PORT JEFFERSON STATION", "PORT WASHINGTON", "PORT WASHINGTON NORTH", "QUIOGUE", "QUOGUE", "REMSENBURG", "RIDGE", "RIVERHEAD", "RIVERSIDE", "ROCKVILLE CENTRE", "ROCKY POINT", "RONKONKOMA", "ROOSEVELT", "ROSLYN", "ROSLYN ESTATES", "ROSLYN HARBOR", "ROSLYN HEIGHTS", "RUSSELL GARDENS", "SADDLE ROCK", "SADDLE ROCK ESTATES", "SAG HARBOR", "SAGAPONACK", "SALISBURY", "SALTAIRE", "SANDS POINT", "SAYVILLE", "SEA CLIFF", "SEAFORD", "SEARINGTOWN", "SELDEN", "SETAUKET", "SHELTER ISLAND", "SHELTER ISLAND HEIGHTS", "SHINNECOCK HILLS", "SHIRLEY", "SHOREHAM", "SMITHTOWN", "SOUND BEACH", "SOUTH FARMINGDALE", "SOUTH FLORAL PARK", "SOUTH HEMPSTEAD", "SOUTH HUNTINGTON", "SOUTH VALLEY STREAM", "SOUTHAMPTON", "SOUTHOLD", "SPEONK", "SPRINGS", "ST. JAMES", "STEWART MANOR", "STONY BROOK", "STONY BROOK UNIVERSITY", "SYOSSET", "TERRYVILLE", "THOMASTON", "TUCKAHOE", "UNIONDALE", "UNIVERSITY GARDENS", "UPPER BROOKVILLE", "VALLEY STREAM", "VILLAGE OF THE BRANCH", "WADING RIVER", "WAINSCOTT", "WANTAGH", "WATER MILL", "WEST BABYLON", "WEST BAY SHORE", "WEST HAMPTON DUNES", "WEST HEMPSTEAD", "WEST HILLS", "WEST ISLIP", "WEST SAYVILLE", "WESTBURY", "WESTHAMPTON", "WESTHAMPTON BEACH", "WHEATLEY HEIGHTS", "WILLISTON PARK", "WOODBURY", "WOODMERE", "WOODSBURGH", "WYANDANCH", "YAPHANK"]

try:
	# National Transportation Safety Board (NTSB) Case Analysis and Reporting Online (CAROL) database page is here: https://data.ntsb.gov/carol-main-public/landing-page
	url = "https://data.ntsb.gov/carol-main-public/api/Query/Main"
	# The limit can be up to 100.
	limit = 100
	# Start the offset at 0.
	offset = 0
	initial_payload = {"ResultSetSize":str(limit),"ResultSetOffset":offset,"QueryGroups":[{"QueryRules":[{"FieldName":"NTSBNumber","RuleType":0,"Values":[],"Columns":["Event.NTSBNumber"],"Operator":"search engine"},{"FieldName":"Mode","RuleType":0,"Values":[],"Columns":["Event.Mode"],"Operator":"is"},{"FieldName":"EventDate","RuleType":0,"Values":[],"Columns":["Event.EventDate"],"Operator":"is"},{"FieldName":"City","RuleType":0,"Values":[],"Columns":["Event.City"],"Operator":"search engine"},{"FieldName":"State","RuleType":0,"Values":["NY"],"Columns":["Event.State"],"Operator":"is"},{"FieldName":"Country","RuleType":0,"Values":[],"Columns":["Event.Country"],"Operator":"is"},{"FieldName":"HighestInjury","RuleType":0,"Values":[],"Columns":["Event.HighestInjury"],"Operator":"is"},{"FieldName":"OriginalPublishedDate","RuleType":0,"Values":[],"Columns":["Event.OriginalPublishedDate"],"Operator":"is"},{"FieldName":"AircraftCategory","RuleType":0,"Values":[],"Columns":["Aircraft.AircraftCategory"],"Operator":"is"},{"FieldName":"EngineType","RuleType":0,"Values":[],"Columns":["Aircraft.EngineType"],"Operator":"is"},{"FieldName":"RegistrationNumber","RuleType":0,"Values":[],"Columns":["Aircraft.RegistrationNumber"],"Operator":"search engine"},{"FieldName":"RegulationFlightConductedUnder","RuleType":0,"Values":[],"Columns":["AviationOperation.RegulationFlightConductedUnder"],"Operator":"is"},{"FieldName":"RecNum","RuleType":0,"Values":[],"Columns":["Recs.Srid","Recs.SridCleaned"],"Operator":"search engine"},{"FieldName":"RecsSubject","RuleType":0,"Values":[],"Columns":["Recs.Subject"],"Operator":"search engine"},{"FieldName":"AddresseeName","RuleType":0,"Values":[],"Columns":["Recs.AddresseeName"],"Operator":"search engine"}],"AndOr":"And"}],"AndOr":"And","SortColumn":None,"SortDescending":True,"TargetCollection":"cases","SessionId":000000}
	headers = {"Content-Type": "application/json"}
	# "requests" documentation page is here: https://docs.python-requests.org/en/master/user/quickstart/
	initial_request = requests.post(url, data=json.dumps(initial_payload), headers=headers, verify=False)
	# We are creating an empty list called "results".
	results = []
	# As we go through each page of the dataset, we are going to scrape that page of the dataset.
	count = initial_request.json()["ResultListCount"]
	i = 0
	while i < count / limit:
		offset = i * limit
		loop_payload = {"ResultSetSize":str(limit),"ResultSetOffset":offset,"QueryGroups":[{"QueryRules":[{"FieldName":"NTSBNumber","RuleType":0,"Values":[],"Columns":["Event.NTSBNumber"],"Operator":"search engine"},{"FieldName":"Mode","RuleType":0,"Values":[],"Columns":["Event.Mode"],"Operator":"is"},{"FieldName":"EventDate","RuleType":0,"Values":[],"Columns":["Event.EventDate"],"Operator":"is"},{"FieldName":"City","RuleType":0,"Values":[],"Columns":["Event.City"],"Operator":"search engine"},{"FieldName":"State","RuleType":0,"Values":["NY"],"Columns":["Event.State"],"Operator":"is"},{"FieldName":"Country","RuleType":0,"Values":[],"Columns":["Event.Country"],"Operator":"is"},{"FieldName":"HighestInjury","RuleType":0,"Values":[],"Columns":["Event.HighestInjury"],"Operator":"is"},{"FieldName":"OriginalPublishedDate","RuleType":0,"Values":[],"Columns":["Event.OriginalPublishedDate"],"Operator":"is"},{"FieldName":"AircraftCategory","RuleType":0,"Values":[],"Columns":["Aircraft.AircraftCategory"],"Operator":"is"},{"FieldName":"EngineType","RuleType":0,"Values":[],"Columns":["Aircraft.EngineType"],"Operator":"is"},{"FieldName":"RegistrationNumber","RuleType":0,"Values":[],"Columns":["Aircraft.RegistrationNumber"],"Operator":"search engine"},{"FieldName":"RegulationFlightConductedUnder","RuleType":0,"Values":[],"Columns":["AviationOperation.RegulationFlightConductedUnder"],"Operator":"is"},{"FieldName":"RecNum","RuleType":0,"Values":[],"Columns":["Recs.Srid","Recs.SridCleaned"],"Operator":"search engine"},{"FieldName":"RecsSubject","RuleType":0,"Values":[],"Columns":["Recs.Subject"],"Operator":"search engine"},{"FieldName":"AddresseeName","RuleType":0,"Values":[],"Columns":["Recs.AddresseeName"],"Operator":"search engine"}],"AndOr":"And"}],"AndOr":"And","SortColumn":None,"SortDescending":True,"TargetCollection":"cases","SessionId":000000}
		loop_request = requests.post(url, data=json.dumps(loop_payload), headers=headers, verify=False)
		for result in loop_request.json()["Results"]:
			row = { field_group["FieldName"]: ", ".join(field_group["Values"]) for field_group in result["Fields"] }
			# Only completed investigations have links to their dockets.
			row["DocketUrl"] = "https://data.ntsb.gov/Docket?ProjectID=" + row["Mkey"]
			if row["City"].upper() in places:
				results.append(row)
		i += 1
	# "pandas" documentation page is here: https://pandas.pydata.org/docs/index.html
	df = pd.DataFrame(results)
	df.to_csv("csv/federal-transportation-investigations.csv", index=False)
except:
	pass